#  Overview
This is the source codes of the baselines in [JOVA](https://pubmed.ncbi.nlm.nih.gov/32860883/). The source code of the entire project can be found [here](https://github.com/bbrighttaer/jova). In the project, the works used as baselines are:
- [SimBoost](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5395521/)
- [KronRLS](https://academic.oup.com/bib/article/16/2/325/246479)
- [IVPGAN](https://ieeexplore.ieee.org/document/9067510)
- ECFP-PSC, based on [PADME-ECFP](https://arxiv.org/abs/1807.09741)
- GraphConv-PSC, based on [PADME-GraphConv](https://arxiv.org/abs/1807.09741)
- CPI-Reg, based on [CPI](https://academic.oup.com/bioinformatics/article/35/2/309/5050020)

The implementation information are presented in the paper.
work for Drug-Target Indication (DTI) predictions but was not included in the 
write-up.

In this documentation, we explain the processes needed to run each of the methods mentioned above.
We assume that a Linux OS is in use.

# Requirements
## Dependencies

| Library/Project                                              | Version     |
|--------------------------------------------------------------|-------------|
| Python                                                       | 3.7         |
| [RDKit](https://anaconda.org/rdkit/rdkit)                    | 2019.09.3.0 |
| [Pytorch](https://pytorch.org/get-started/locally/)          | 1.3.0       |
| [Numpy](https://pypi.org/project/numpy/)                     | 1.18.4      |
| [XGBoost](https://pypi.org/project/xgboost/)                 | 0.90        |
| [Pandas](https://pypi.org/project/pandas/)                   | 1.0.3       |
| [Seaborn](https://pypi.org/project/seaborn/)                 | 0.9.0       |
| [Soek](https://github.com/bbrighttaer/soek)                  | 0.0.1       |
| [torch-scatter](https://github.com/rusty1s/pytorch_scatter)  | 2.0.5       |
| [BioPython](https://biopython.org/wiki/Download)             | 1.76        |
| [Scikit-Learn](https://scikit-learn.org/stable/install.html) | 0.23.1       |
| [tqdm](https://github.com/tqdm/tqdm)                         | 4.35.0      |

To install the dependencies, we suggest you install 
[Anaconda](https://www.anaconda.com/products/individual) 
first and then follow the commands below:

1. Create anaconda environment
    ```bash
    $ conda create -n jova python=3.7
    ```
2. Activate environment
   ```bash
   $ conda activate jova
   ```
3. Install the dependencies above according to their official websites or documentations.
For instance, you can install `XGBoost` using the command
   ```bash
   $ pip install xgboost==0.90
   ```

## Datasets
### Regression
The [Davis](./data/davis_data), [Metz](./data/metz_data), [KIBA](./data/KIBA_data), 
and [Toxcast](./data/full_toxcast) datasets are for regression and from 
[PADME](https://github.com/simonfqy/PADME). 

The [EGFR_1M17](./data/egfr_1M17), [EGFR Case Study](./data/egfr_case_study), 
and [EGFR unfiltered](./data/egfr_unfiltered) were constructed in our project for
the case studies described in the paper. In [EGFR_1M17](./data/egfr_1M17) 
the [1M17](https://www.rcsb.org/structure/1M17) sequence of EGFR is used 
whereas the EGFR UniProt sequence is used in [EGFR Case Study](./data/egfr_case_study).
The compounds in [EGFR_1M17](./data/egfr_1M17) and [EGFR Case Study](./data/egfr_case_study) are
the DrugBank compounds which are not part of the [KIBA](./data/KIBA_data) dataset.

### Classification
The [Celegans](./data/celegans_data) and [Human](./data/human_data) datasets are for binary classification 
and from the [CPI](https://github.com/masashitsubaki/CPI_prediction) project.

### Protein
#### Regression experiments
The [protein](./data/protein) directory contains the files for facilitating learning protein embeddings.
We constructed the [protein_words_dict.pkl](./data/protein/protein_words_dict.pkl) file following the
Prot2Vec section described in the [supplementary document](./jova_paper_sup.pdf) using 
all `prot_info.csv` files in [data](./data). 
Afterwards, the profile of each protein in, for instance, `data/davis_data/prot_desc.csv`
 and `../../data/egfr_1M17/prot_desc_pdb_1M17.csv` is generated by executing:

```bash
$ python build_prot_vocabs.py  --vocab ../../data/protein/protein_words_dict.pkl --prot_desc_path ../../data/davis_data/prot_desc.csv --prot_desc_path ../../data/egfr_1M17/prot_desc_pdb_1M17.csv
```

#### Classification experiments
In the binary classification case we construct the protein profile for each dataset separately.
For instance, on the [Human](./data/human_data) dataset, we construct the profile using:
```bash
$ python build_prot_vocabs_cpi --prot_desc_path ../../data/human_data/prot_desc.csv
```
___

# Usage
First ensure you are in the project directory and set it up with:
```bash
$ pip install -e .
```

Then `cd` into the `dti` directory of the project with:
```bash
$ cd proj/dti/
```

## Regression
- `simboost.py`

    To run the SimBoost implementation, you first need to run the Matrix Factorization (MF) experiment.
    The MF experiment produces two files after execution. The first is a `.mod` file which stores the 
    weights of the trained model and the second has the suffix `_mf_simboost_data_dict.pkl` which is a 
    python dictionary of compound-target features needed in the SimBoost feature construction stage.
    This can be achieved with:
    ```bash
    $ python mf.py --dataset_name davis --dataset_file ../../data/davis_data/restructured.csv --prot_desc_path ../../data/davis_data/prot_desc.csv --comp_view ecfp8 --prot_view psc
    ```
    Once the `*__mf_simboost_data_dict.pkl` is created, you can run the SimBoost experiment
    using:
    ```bash
    $ python simboost.py --dataset_name davis --dataset_file ../../data/davis_data/restructured.csv --prot_desc_path ../../data/davis_data/prot_desc.csv --model_dir ./model_dir/davis --filter_threshold 6 --comp_view ecfp8 --prot_view psc --fold_num 5 --mf_simboost_data_dict davis_MF_kiba_ecfp8_psc_mf_simboost_data_dict.pkl
    ```
    
- `kronrls.py`
    A sample command to run the KronRLS experiment on the KIBA dataset is in [kronrls_cv.sh](./proj/dti/kronrls_cv.sh).
- `train_joint.py`
   This script trains a model similar to that integrates the ECFP and GraphConv features
   of a compound and the PSC of a protein using the MSE loss function. 
   [train_joint_cv.sh](./proj/dti/train_joint.py) shows a sample run command.
- `train_joint_gan.py`
   The IVPGAN baseline. Revised implementation of the [initial version](https://github.com/bbrighttaer/ivpgan/blob/master/proj/dti/train_joint_gan.py)
- `singleview.py`
   This script trains models that use unimodal representation of compounds and targets.
   A sample run command on the Metz dataset can be found in [singleview.sh](./proj/dti/singleview.sh).
   
   To train an ECFP-PSC model, set the `comp_view` and `prot_view` flags to `--comp_view ecfp --prot_view psc`
   in [singleview.sh](./proj/dti/singleview.sh)
   
   The possible compound views are `[psc, rnn, pcnn, p2v]` and the possible target views are
   `[ecfp4, ecfp8, weave, gconv, gnn]`. 
- `cpi_baseline.py`
   Implements the CPI-reg baseline. Thus, `--comp_view gnn --prot_view pcnna`.
   Sample run file: [cpi_baseline.sh](./proj/dti/cpi_baseline.sh)
   
   The `pcnn/pcnna` and `gnn` views are due to 
   [Tsubaki et al.](https://academic.oup.com/bioinformatics/article/35/2/309/5050020).

## Classification
- `cpi_baseline_bin.py`

   Follows the implementation of 
   [CPI_prediction](https://github.com/masashitsubaki/CPI_prediction).
   
   Sample run file: [cpi_baseline_bin_cv_human.sh](./proj/dti/cpi_baseline_bin_cv_human.sh)

To evaluate a model you will need to specify the `--eval`, `--eval_model_name`, and `--model_dir` flags.
Please see the command line arguments in each file for more on model evaluation.

## Others
- `worker_jova.py`
    
    Used to preprocess experiment data for analysis.
# Credits
We acknowledge the authors of the PADME project for their work. 
Our project uses the data, data loading, and metric procedures published by 
their work and we're grateful. 

We acknowledge the authors and contributors 
of the DeepChem project for their implementations of the Graph Convolution, Weave, 
and other featurization schemes; the GraphConv and Weave implementations in this 
work are basically our Pytorch translations of their initial works.

We also acknowledge the [CPI_prediction](https://github.com/masashitsubaki/CPI_prediction)
project for the `PCNNA` and `GNN` implementations. We re-organized the `GNN` implementation
into a DeepChem compatible featurization scheme in this project.

Thanks to [Yulkang](https://github.com/yulkang) for the work in 
[numpytorch.py](https://github.com/yulkang/pylabyk/blob/master/numpytorch.py).

# Cite
```bibtex
@article{Agyemang2020,
archivePrefix = {arXiv},
arxivId = {2005.00397},
author = {Agyemang, Brighter and Wu, Wei-Ping and Kpiebaareh, Michael Yelpengne 
and Lei, Zhihua and Nanor, Ebenezer and Chen, Lei},
doi = {10.1016/j.jbi.2020.103547},
eprint = {2005.00397},
issn = {1532-0464},
journal = {Journal of Biomedical Informatics},
keywords = {Drugâ€“target interactions,Machine learning,Represen,drug,target interactions},
number = {August},
pages = {103547},
publisher = {Elsevier Inc.},
title = {{Multi-View Self-Attention for Interpretable Drug-Target Interaction Prediction}},
url = {https://pubmed.ncbi.nlm.nih.gov/32860883/},
volume = {110},
year = {2020}
}
```


